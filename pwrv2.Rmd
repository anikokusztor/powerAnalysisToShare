---
title: "PowerAnalysis"
author: "Aniko Kusztor"
date: "2024-10-28"
output: html_document
---

Written by: Anik√≥ Kusztor

### Explanation

1.  **Function Definition**: `simData` simulates data for a given sample size (nsub parameter) with a given coefficient (CDSslope parameter). The means, standard deviations and other parameters were based on the pilot data.
2.  **Simulation Loop**: For each sample size, it simulates data, fits the model, and extracts p-values.
3.  **Power Calculation and Plot**: Computes the proportion of significant p-values and visualizes the power curve.

Each chunk in this notebook can be run sequentially, allowing for interactive analysis and visualization.

```{r setup, include=FALSE}
# Load  libraries
library(dplyr)
library(truncnorm)
library(ordinal)
library(ggplot2)
library(brms)
library(cmdstanr)

```

First we need to simulate data. We have 25 emotion categories, in each category we have 20 different videos adding up to 500 stimuli. We simulate the random intercepts for each stimulus and then select 75 videos (3 random videos from each category). Next, for each participant we simulate CDS scores and random intercept. Finally, we simulate the emotional intensity ratings, which are on an order Likert-scale between 1-8. Since we plan to analyse the data with cumulative logit models (a.k.a. ordinal logistic regression), we will generate the ratings via the following steps:

- We use the cut-off point from the pilot data. They determine the initial probability of each ordinal outcome. In other words, they determine how likely each emotional rating option is. 

- We set-up a linear predictor for each rating category. We include the random effects here and also the CDS scores and their slope coefficient.

- We compute cumulative probabilities for each threshold, which are then used to compute probabilities for each ordinal category. 

- Finally, we simulate ratings based on the probabilities.

```{r}
simData <- function(outdata, nsub, CDSslope) {
  
  # Define unique emotion categories
  emo_cats <- data.frame(c("Disgust", "AestheticAppreciation", "Awe", "Boredom", "Fear", "Romance",
                           "Amusement", "Joy", "Adoration", "Surprise", "Interest", "Sadness",
                           "Craving", "Calmness", "Horror", "Entrancement", "Anxiety", "EmpathicPain",
                           "Anger", "Confusion", "Awkwardness", "Excitement", "Admiration", "Relief", "Satisfaction"))
  names(emo_cats) <- "EmoCat2"
  
  # Repeat each emotion category 20 times
  stimuli_ID <- data.frame(rep(emo_cats$EmoCat2, each = 20))
  names(stimuli_ID) <- "EmoCat2"
  stimuli_ID$num <- rep(1:20, times = 25)
  stimuli_ID$stimID <- paste0(stimuli_ID[,1], stimuli_ID[,2])
  
  # Generate random intercept for stimuli
  SDstim <- sqrt(1.15)
  stimuli_ID$stimRandIntercept <- rtruncnorm(nrow(stimuli_ID), a = 0, b = Inf, mean = 0, sd = SDstim)
  
  # Generate data for each subject
  for (i in 1:nsub) {
    
    # Randomly select 3 stimID for each emotion category
    sampled_stim <- stimuli_ID %>%
      group_by(EmoCat2) %>%
      sample_n(3) %>%
      ungroup()
    
    artificial_data <- data.frame(sampled_stim$stimID)
    colnames(artificial_data) <- "vidName_Cat"
    artificial_data$stimRandIntercept <- sampled_stim$stimRandIntercept
    artificial_data$EmoCat2 <- sampled_stim$EmoCat2
    
    # Simulate CDS scores
    simCDSsum <- round(rnorm(1, 38, 34))
    while (simCDSsum >= 220 || simCDSsum <= 0) { 
      simCDSsum <- round(rnorm(1, 38, 34)) 
    }
    artificial_data$CDSstate <- rep(simCDSsum, length(sampled_stim$stimID))
    artificial_data$PROLIFIC_PID <- rep(i, length(sampled_stim$stimID))
    artificial_data$CDSstateS <- (artificial_data$CDSstate - 38) / 34 #scale CDS score
    
    # Subject random intercept
    SDsub <- sqrt(1.16)
    artificial_data$subRandIntercept <- rep(rnorm(1, mean = 0, sd = SDsub), length(sampled_stim$stimID))
    
    #add ratings
    # based mean and SD of estimates in all models on the pilot data 
    # these need to maintain b01>b02>...>b07
    
    b01 <- -2.91
    b02 <- -1.88
    b03 <- -0.91
    b04 <- 0.05
    b05 <- 1.02
    b06 <- 1.99
    b07 <- 2.96
    
    artificial_data$logodds1 <- b01 - (artificial_data$subRandIntercept + artificial_data$stimRandIntercept + ((CDSslope) * (artificial_data$CDSstateS)))
    artificial_data$logodds2 <- b02 - (artificial_data$subRandIntercept + artificial_data$stimRandIntercept + ((CDSslope) * (artificial_data$CDSstateS)))
    artificial_data$logodds3 <- b03 - (artificial_data$subRandIntercept + artificial_data$stimRandIntercept + ((CDSslope) * (artificial_data$CDSstateS)))
    artificial_data$logodds4 <- b04 - (artificial_data$subRandIntercept + artificial_data$stimRandIntercept + ((CDSslope) * (artificial_data$CDSstateS)))
    artificial_data$logodds5 <- b05 - (artificial_data$subRandIntercept + artificial_data$stimRandIntercept + ((CDSslope) * (artificial_data$CDSstateS)))
    artificial_data$logodds6 <- b06 - (artificial_data$subRandIntercept + artificial_data$stimRandIntercept + ((CDSslope) * (artificial_data$CDSstateS)))
    artificial_data$logodds7 <- b07 - (artificial_data$subRandIntercept + artificial_data$stimRandIntercept + ((CDSslope) * (artificial_data$CDSstateS)))
    
    artificial_data$cprob_2to1 <- plogis(artificial_data$logodds2)
    artificial_data$cprob_3to1 <- plogis(artificial_data$logodds3)
    artificial_data$cprob_4to1 <- plogis(artificial_data$logodds4)
    artificial_data$cprob_5to1 <- plogis(artificial_data$logodds5)
    artificial_data$cprob_6to1 <- plogis(artificial_data$logodds6)
    artificial_data$cprob_7to1 <- plogis(artificial_data$logodds7)
    
    artificial_data$prob_1 <- plogis(artificial_data$logodds1)
    artificial_data$prob_2 <- artificial_data$cprob_2to1 - artificial_data$prob_1
    artificial_data$prob_3 <- artificial_data$cprob_3to1 - artificial_data$cprob_2to1
    artificial_data$prob_4 <- artificial_data$cprob_4to1 - artificial_data$cprob_3to1
    artificial_data$prob_5 <- artificial_data$cprob_5to1 - artificial_data$cprob_4to1
    artificial_data$prob_6 <- artificial_data$cprob_6to1 - artificial_data$cprob_5to1
    artificial_data$prob_7 <- artificial_data$cprob_7to1 - artificial_data$cprob_6to1
    artificial_data$prob_8 <- 1 - artificial_data$cprob_7to1
    
    
    artificial_data$emoIntense <- apply(X = artificial_data[,grep("^prob_", names(artificial_data))], MARGIN = 1, # MARGIN = 1 indicates you are applying FUN per rows 
                                       FUN = function(x) sample(1:8, size = 1, prob = x))


    outdata <- rbind(outdata, artificial_data)
  }
  
  return(outdata)
}

```

Next we are running simulations. In each run, we simulate a new dataset, then select 1 emotion category and subset the data. After that, we fit a cumulative logit model with random intercepts for participant and stimuli. Finally we extract the p-values.

This can take up to an hour for one effect size with the current parameters. To test the simulation, decrease values in nsim ans sample_sizes variables. 

```{r}
# Set parameters
set.seed(786)  # For reproducibility
nsim <- 100
sample_sizes <- c(250,500,750)
CDSslope <- 0.3


p_values <- data.frame()
colnum <- 0

for (iii in sample_sizes){
  colnum <- colnum + 1
  for (ii in 1:nsim){
    tstartfull <- Sys.time()
    tstartfull_format <- format(tstartfull, "%Y-%m-%d %H:%M:%S")  # Force readable format
    cat('Starting simulation', ii, 'of', nsim, 'at', tstartfull_format, '\n')

  simdataset <- data.frame()  # Use data.table for efficiency?
  simdataset <- simData(simdataset,iii,CDSslope)
  
  simdataset$emoIntenseF <- ordered(simdataset$emoIntense)
  simdataset$vidName_Cat <- factor(simdataset$vidName_Cat)
  simdataset$PROLIFIC_PID <- factor(simdataset$PROLIFIC_PID)
  
  emo_cats <- unique(simdataset$EmoCat2)
  subset_data <- subset(simdataset, EmoCat2 == "Admiration") #this is just a random choice
  # Fit the model to the simulated data
  model <- try(clmm(emoIntenseF ~ CDSstateS + (1 | PROLIFIC_PID) + (1 | vidName_Cat), 
                     data = subset_data, link = "logit"), silent = TRUE)
  
  # Extract p-value if the model converged successfully
  if (inherits(model, "clmm")) {
    p_values[ii,colnum] <- summary(model)$coefficients["CDSstateS", "Pr(>|z|)"]
  } else {
    p_values[ii,colnum] <- NA  # Mark simulations with non-converged models
  }
  print(Sys.time()-tstartfull)
  }
  
}
cat("Simulation done!","\n")

```

Okay, now let's see the data. We calculate the proportions of p-value below 0.05 and plot them in each sample sizes.

```{r}

# Calculate power for each sample size
power_results <- colMeans(p_values < 0.05, na.rm = TRUE)
plot_data <- data.frame(Sample_Size = sample_sizes, Power = power_results)

# Create the power curve plot
ggplot(plot_data, aes(x = Sample_Size, y = Power)) +
  geom_line(linewidth = 1, color = "#007eb2") +
  geom_point(size = 2, color = "black") +
  #scale_x_continuous(limits=c(95,755)) +
  scale_y_continuous(limits=c(0,1.0), breaks=seq(0,1.0,0.2)) +
  labs(title = "Power Curve",x = "Sample Size", y = "Power") +
  theme_bw(base_size = 18)

```

### Plot simulated data

To reproduce our plot, run the section below. This imports simulated data from 100 simulation runs, with 3 sample sizes (250, 500, 750) and with 3 effec sizes (0.1, 0.2, 0.3).

```{r}
# import already simulated data
p_values_sim <- readRDS("combined_p_values_100run_ssize250-500-750.rds")
# Define sample sizes c
ssizes <- c(250, 500, 750)

# Calculate power for each sample size and effect size
plot_data <- data.frame()

# Loop through each effect size
for (effect_size in unique(p_values_sim$Effect_Size)) {
  # Subset data for the current effect size
  subset_data <- subset(p_values_sim, Effect_Size == effect_size)
  # Calculate power for each sample size 
  power_results <- sapply(subset_data[, c("V1", "V2", "V3")], function(column) {
    mean(column < 0.05, na.rm = TRUE)  # Calculate power (proportion of significant p-values)
  })
  # Create a data frame for the current effect size
  effect_data <- data.frame(
    Sample_Size = ssizes,
    Power = power_results,
    Effect_Size = paste("Effect Size", effect_size)
  )
  # Append
  plot_data <- rbind(plot_data, effect_data)
}


ggplot(plot_data, aes(x = Sample_Size, y = Power, color = Effect_Size, group = Effect_Size)) +
  geom_line(size = 1) +
  geom_point(size = 2, color = "black") +
  scale_x_continuous(limits=c(245,755), breaks=ssizes) +
  scale_y_continuous(limits=c(0,1.0), breaks=seq(0,1.0,0.2)) +
  labs(title = "Power Curve",x = "Sample Size", y = "Power") +
  theme_bw(base_size = 18)


```

### Bayesian model example

To test the Bayesian model comparison code, we simulate data using the same function as before. We set-up the priors and formulas. Then we specify the brm models. The current specification are optimised for within-chain parallelisation using the cmdstanr backend on 8 available cores. In addition, we normally would use higher iter numbers (i.e. MCMC samples) as this has been recommended for calculating the Bayes Factor reliably. (See: Schad et al., 2023, DOI: https://doi.org/10.1037/met0000472)

To test this code, we recommend to decrease the participant number. We have also decreased the iter and warmup values from 10000 and 2000 to 2000 and 500. 

```{r}

priors_mixed <- c(
  set_prior('normal(0, 1)', class = 'b'),
  set_prior('exponential(1)', class = 'sd', group = 'vidName_Cat'),
  set_prior('exponential(1)', class = 'sd', group = 'PROLIFIC_PID')) 

priors_mixednull <- c(
  set_prior('exponential(1)', class = 'sd', group = 'vidName_Cat'),
  set_prior('exponential(1)', class = 'sd', group = 'PROLIFIC_PID')) 

model <- NaN
modelnull<- NaN

# formulas for full and null model
formulanull = emoIntenseF ~ 1 + (1|PROLIFIC_PID) + (1|vidName_Cat)
formula = emoIntenseF ~ 1 + CDSstateS + (1|PROLIFIC_PID) + (1|vidName_Cat)


simdataset <- data.frame()  # Use data.table for efficiency
simdataset <- simData(simdataset,500,-0.1) # simulate data
  
simdataset$emoIntenseF <- ordered(simdataset$emoIntense)
simdataset$vidName_Cat <- factor(simdataset$vidName_Cat)
simdataset$PROLIFIC_PID <- factor(simdataset$PROLIFIC_PID)
  
emo_cats <- unique(simdataset$EmoCat2)
subset_data <- subset(simdataset, EmoCat2 == "Admiration") #this is just a random choice

model<- brm(formula = formula,
            family = cumulative,
            prior = priors_mixed,
            init = 0.2,
            chain = 4,
            cores = 4,
            backend = "cmdstanr",
            threads = threading(2),
            iter = 2000, #10000,
            warmup = 500, #2000,
            control=list(adapt_delta=0.99,max_treedepth=15),
            save_pars = save_pars(all = TRUE),
            sig_figs = 10,
            data = subset_data)
    
modelnull <- brm(formula = formulanull,
                 family = cumulative,
                 prior = priors_mixednull,
                 init = 0.2,
                 chain = 4,
                 cores = 4,
                 backend = "cmdstanr",
                 threads = threading(2),
                 iter = 2000, #10000,
                 warmup = 500, #2000,
                 control=list(adapt_delta=0.99,max_treedepth=15),
                 save_pars = save_pars(all = TRUE),
                 sig_figs = 10,
                 data = subset_data)
  
bayes_factor(model,modelnull)$bf

```



_For question and comments: kusztoraniko@gmail.com_
